# Repositorio de Prueba TÃ©cnica Sudata

Este repositorio contiene la resoluciÃ³n de distintos ejercicios como parte de una prueba tÃ©cnica. Cada ejercicio se encuentra organizado en su propia carpeta con cÃ³digo fuente, scripts, y un `README.md` explicativo.

---

## ğŸ“ Estructura general

```text
Ejercicio 1/
â”œâ”€â”€ replicate.py        # Script Python de replicaciÃ³n
â”œâ”€â”€ create_db.py        # Script Python para crear la base de datos y las tablas en PostgreSQL
â”œâ”€â”€ csv_to_db.py        # Script Python para poblar las tablas con datos
â”œâ”€â”€ .env.example        # Ejemplo de archivo con variables de entorno
â”œâ”€â”€ README.md           # DocumentaciÃ³n principal para este ejercicio
â””â”€â”€ screenshots/        # Capturas de pantalla del Programador de Tareas en Windows
    â”œâ”€â”€ Esqueda DB      # Screenshot del esquema creado en Supabase
    â””â”€â”€ pasos.png       # Imagenes explicativas

Ejercicio 2/
â”œâ”€â”€ data_historica.py   # Script principal para extraer las cotizaciones histÃ³ricas desde la API del BCRA
â”œâ”€â”€ incremental.py      # Script para ingresar los nuevos datos a partir de la ultima fecha registrada en la base de datos
â”œâ”€â”€ utils.py            # Todas las funciones necesarias para mantener el cÃ³digo limpio y escalable
â”œâ”€â”€ .env.example        # Ejemplo con variables necesarias
â””â”€â”€ README.md           # DocumentaciÃ³n detallada del Ejercicio 2

Ejercicio 3/
â”œâ”€â”€ .env                 # variables de entorno (no subir)
â”œâ”€â”€ bloqueos_tecnicos.py # detectar Cloudflare / CAPTCHA / rate-limits
â”œâ”€â”€ csv_to_db_supabase.py# leer CSV, limpiar/transformar y cargar a Supabase
â”œâ”€â”€ permite_scrap.py     # comprobar robots.txt / permiso de crawling
â”œâ”€â”€ scraping.py          # scraper para Argenprop (genera CSV)
â””â”€â”€ README.md            # DocumentaciÃ³n especÃ­fica del Ejercicio 3

â””â”€â”€ README.md           # Este README global
````

---

## ğŸ“Œ Contenidos por ejercicio

### ğŸ”¹ Ejercicio 1: ReplicaciÃ³n PostgreSQL â†’ Supabase

* Crear una base PostgreSQL local (`ventas_origen`)
* Crear y poblar tablas con datos desde CSV
* Replicar los datos a una base espejo en Supabase (`ventas_espejo`)
* Automatizar la replicaciÃ³n diaria con Task Scheduler (Programador de Tareas de Windows)

Ver [Ejercicio 1/README.md](Ejercicio%201/README.md) para mÃ¡s detalles.

---

### ğŸ”¹ Ejercicio 2: ExtracciÃ³n incremental desde la API del BCRA usando Render cron jobs

* Se conecta a la [API oficial del BCRA](https://www.bcra.gob.ar/BCRAyVos/catalogo-de-APIs-banco-central.asp) para obtener las cotizaciones del dÃ³lar tipo vendedor.
* La extracciÃ³n es **incremental**, es decir, se descarga solo la informaciÃ³n nueva desde la Ãºltima fecha registrada.
* Se utiliza una base PostgreSQL en la nube desplegada en **Render**.
* La actualizaciÃ³n semanal se realiza mediante un **cron job configurado en Render** (sin necesidad de Task Scheduler ni GitHub Actions).

Ver [Ejercicio 2/README.md](Ejercicio%202/README.md) para mÃ¡s detalles.

---

### ğŸ”¹ Ejercicio 3: Web Scraping â†’ Limpieza â†’ Carga a Supabase

* Incluye scripts para comprobar permisos en robots.txt y detectar bloqueos tÃ©cnicos antes de realizar el scraping.
* Scraping de listados pÃºblicos (ej. Argenprop â€” terrenos/venta/posadas) con Selenium. 
* Limpieza y transformaciÃ³n del CSV resultante del scraping y carga en base de datos PostgreSQL alojada en Supabase.
* El flujo recomendado es: verificar permisos â†’ detectar bloqueos â†’ ejecutar scraping â†’ cargar datos a Supabase.

Ver [Ejercicio 3/README.md](Ejercicio%203/README.md) para mÃ¡s detalles.

---

## âœ… Recomendaciones de uso

* Ingresar a cada carpeta de ejercicio para acceder a sus scripts y documentaciÃ³n especÃ­fica.
* Usar entornos virtuales para instalar dependencias locales.

---

## ğŸ“„ Licencia

Este repositorio estÃ¡ disponible bajo la licencia MIT.